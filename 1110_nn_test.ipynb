{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72d8b8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3edcd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.unsqueeze(torch.linspace(-1,1,100),dim=1)\n",
    "y = x.pow(3)+0.1*torch.randn(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "125fe6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 0, 13,  6, 14, 18,  9]), array([ 7, 15,  5,  4,  8,  3]), array([17, 12,  2, 11, 10, 16]), array([ 1, 19])]\n"
     ]
    }
   ],
   "source": [
    "mini_batch_size=6\n",
    "n_states = 20  # memory记录数量=20\n",
    "batch_start = np.arange(0, n_states, mini_batch_size)  # 每个batch开始的位置[0,5,10,15]\n",
    "indices = np.arange(n_states, dtype=np.int64)  # 记录编号[0,1,2....19]\n",
    "np.random.shuffle(indices)  # 打乱编号顺序[3,1,9,11....18]\n",
    "mini_batches = [indices[i:i + mini_batch_size] for i in batch_start] \n",
    "print(mini_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8566b458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x , y =(Variable(x),Variable(y))\n",
    "\n",
    "plt.scatter(x.data,y.data)\n",
    "# 或者采用如下的方式也可以输出x,y\n",
    "# plt.scatter(x.data.numpy(),y.data.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba91879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(self).__init__()\n",
    "        pass\n",
    "    def forward(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "405c34bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,n_input,n_hidden,n_output):\n",
    "        super(Net,self).__init__()\n",
    "        self.hidden1 = nn.Linear(n_input,n_hidden)\n",
    "        self.hidden2 = nn.Linear(n_hidden,n_hidden)\n",
    "        self.predict = nn.Linear(n_hidden,n_output)\n",
    "    def forward(self,input):\n",
    "        out = self.hidden1(input)\n",
    "        out = F.relu(out)\n",
    "        out = self.hidden2(out)\n",
    "        out = F.sigmoid(out)\n",
    "        out =self.predict(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfee801e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (hidden1): Linear(in_features=1, out_features=20, bias=True)\n",
      "  (hidden2): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (predict): Linear(in_features=20, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net(1,20,1)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1bde53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(),lr = 0.1)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "# plt.ion()\n",
    "# plt.show()\n",
    "\n",
    "for t in range(5000):\n",
    "    prediction = net(x)\n",
    "    loss = loss_func(prediction,y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "#     if t%5 ==0:\n",
    "#         plt.cla()\n",
    "#         plt.scatter(x.data.numpy(), y.data.numpy())\n",
    "#         plt.plot(x.data.numpy(), prediction.data.numpy(), 'r-', lw=5)\n",
    "#         plt.text(0.5, 0, 'Loss = %.4f' % loss.data, fontdict={'size': 20, 'color': 'red'})\n",
    "#         plt.pause(0.05)\n",
    "\n",
    "# plt.ioff()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7178cc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPOmemory:\n",
    "    def __init__(self, mini_batch_size):\n",
    "        self.states = []  # 状态\n",
    "        self.actions = []  # 实际采取的动作\n",
    "        self.probs = []  # 动作概率\n",
    "        self.vals = []  # critic输出的状态值\n",
    "        self.rewards = []  # 奖励\n",
    "        self.dones = []  # 结束标志\n",
    "\n",
    "        self.mini_batch_size = mini_batch_size  # minibatch的大小\n",
    "\n",
    "    def sample(self):\n",
    "        n_states = len(self.states)  # memory记录数量=20\n",
    "        batch_start = np.arange(0, n_states, self.mini_batch_size)  # 每个batch开始的位置[0,5,10,15]\n",
    "        indices = np.arange(n_states, dtype=np.int64)  # 记录编号[0,1,2....19]\n",
    "        np.random.shuffle(indices)  # 打乱编号顺序[3,1,9,11....18]\n",
    "        mini_batches = [indices[i:i + self.mini_batch_size] for i in batch_start]  # 生成4个minibatch，每个minibatch记录乱序且不重复\n",
    "\n",
    "        return np.array(self.states), np.array(self.actions), np.array(self.probs), \\\n",
    "               np.array(self.vals), np.array(self.rewards), np.array(self.dones), mini_batches\n",
    "\n",
    "    # 每一步都存储trace到memory\n",
    "    def push(self, state, action, prob, val, reward, done):\n",
    "        self.states.append(state)\n",
    "        self.actions.append(action)\n",
    "        self.probs.append(prob)\n",
    "        self.vals.append(val)\n",
    "        self.rewards.append(reward)\n",
    "        self.dones.append(done)\n",
    "\n",
    "    # 固定步长更新完网络后清空memory\n",
    "    def clear(self):\n",
    "        self.states = []\n",
    "        self.actions = []\n",
    "        self.probs = []\n",
    "        self.vals = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b9c6ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actor:policy network\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, n_states, n_actions, cfg):\n",
    "        super(Actor, self).__init__()\n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(n_states, cfg.hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(cfg.hidden_dim, cfg.hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(cfg.hidden_dim, n_actions),\n",
    "            nn.Softmax(dim=-1))\n",
    "\n",
    "    def forward(self, state):\n",
    "        dist = self.actor(state)\n",
    "        dist = Categorical(dist)\n",
    "        return dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c41051ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# critic:value network\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, n_states, hidden_dim):\n",
    "        super(Critic, self).__init__()\n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(n_states, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, 1))\n",
    "\n",
    "    def forward(self, state):\n",
    "        value = self.critic(state)\n",
    "        return value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "906a5391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16.38525582, 13.0674252 ])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def __gaussianSampleData(self, mu, sigma):\n",
    "    # sample N examples\n",
    "    sample_matrix = np.zeros((self.N, self.d))\n",
    "    for j in range(self.d):\n",
    "        sample_matrix[:,j] = np.random.normal(loc=mu[j], scale=sigma[j], size=(self.N,))\n",
    "    if self.v_min is not None and self.v_max is not None:\n",
    "        sample_matrix[:,0:self.d:self.dof] = np.clip(sample_matrix[:,0:self.d:self.dof],  self.v_min[0], self.v_max[0])\n",
    "        sample_matrix[:,1:self.d:self.dof] = np.clip(sample_matrix[:,1:self.d:self.dof],  self.v_min[1], self.v_max[1])\n",
    "        sample_matrix[:,2:self.d:self.dof] = np.clip(sample_matrix[:,2:self.d:self.dof],  self.v_min[-1], self.v_max[-1])\n",
    "    return sample_matrix\n",
    "\n",
    "随机生成一个6维的数组 前四个数范围：[0,0]至 [8,8]的正方形内  后两个 0到7 \n",
    "\n",
    "前四个高斯分布 方差为2\n",
    "\n",
    "def env_reset():\n",
    "    states = np.zeros(6)\n",
    "    mu= np.array([2.57696126, 2.34334736, 6.38525582, 3.0674252])\n",
    "    for i in range(4):\n",
    "        states[i] = np.random.normal(loc=mu[j], scale=2)\n",
    "    states[4]=np.random.uniform(0,7)\n",
    "    states[5]=np.random.uniform(0,7)\n",
    "    states[:4]=  np.clip(states[:4],  0, 8)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e8989ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.16813553, 4.53502492, 5.24310259, 3.15875568, 5.84753346,\n",
       "       0.72930052])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def env_reset():\n",
    "    states = np.zeros(6)\n",
    "    mu= np.array([2.57696126, 2.34334736, 6.38525582, 3.0674252])\n",
    "    for i in range(4):\n",
    "        states[i] = np.random.normal(loc=mu[i], scale=1)\n",
    "    states[4]=np.random.uniform(0,7)\n",
    "    states[5]=np.random.uniform(0,7)\n",
    "    states[:4]=  np.clip(states[:4],  0, 8)\n",
    "    return states\n",
    "env_reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "219a915a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.57696126, 2.34334736, 6.38525582])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu= np.array([2.57696126, 2.34334736, 6.38525582, 3.0674252])\n",
    "mu[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "20cf123c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "limit= np.array([[5,6],[3,4]])\n",
    "# reward, done, _ = get_reward(state,action)\n",
    "\n",
    "# state: start, end , obstcle   长和宽为一的正方形 只要确定左下角的x和y\n",
    "# 轨迹平均起点[2.57696126, 2.34334736] 平均终点[6.38525582, 3.0674252 ])  平均长度为  3.876518563635841\n",
    "\n",
    "# 轨迹限制在加减10以内: [-7,-7]至  [15,15]的正方形内\n",
    "\n",
    "# 起点[-7.42303874, -7.65665264] 至[12.57696126, 12.34334736]\n",
    "# 终点：[-3.61474418, -6.9325748 ]至[16.38525582, 13.0674252 ]\n",
    "\n",
    "\n",
    "\n",
    "# 给定mean的起点终点 fid最小为48 此时mean轨迹完全一样 只是方差不同\n",
    "# state = [x_start,y_start,x_end,y_end,x_obs,y_obs]  维度为6\n",
    "\n",
    "# 先尝试一个via point，此时action维度为3\n",
    "\n",
    "def env_reset():\n",
    "    \n",
    "\n",
    "\n",
    "def get_reward(state, action):\n",
    "       \n",
    "    old_promp=promp\n",
    "    action = action.reshape([-1,3])\n",
    "    t_cond = np.zeros(2+action.shape[0])\n",
    "    t_cond[0]=0\n",
    "    t_cond[-1] = 1 \n",
    "    for i in range(action.shape[0]):\n",
    "        t_cond[i+1]=action[i,2]\n",
    "\n",
    "    q_cond =np.zeros([2+action.shape[0],2])\n",
    "    q_cond[0]= np.array([state[0],state[1]])\n",
    "    q_cond[-1]=np.array([state[2],state[3]])\n",
    "    for i in range(action.shape[0]):\n",
    "        q_cond[i+1]=action[i,:2]\n",
    "        \n",
    "    mu_w_cond_rec, Sigma_w_cond_rec=old_promp.get_basis_weight_parameters()\n",
    "\n",
    "    for i in range(t_cond.shape[0]):\n",
    "        mu_w_cond_rec, Sigma_w_cond_rec = old_promp.get_conditioned_weights(t_cond[i], q_cond[i], mean_w=mu_w_cond_rec, var_w=Sigma_w_cond_rec)\n",
    "\n",
    "    cond_traj = np.zeros([2,100])\n",
    "    sigma_con_array =np.zeros([2,2,100]) \n",
    "    for i in range(len(domain)):\n",
    "        mu_marg_q_con, Sigma_marg_q_con = promp.get_marginal(domain[i], mu_w_cond_rec, Sigma_w_cond_rec)\n",
    "        sigma_con_array[:,:,i] = Sigma_marg_q_con\n",
    "        cond_traj[:,i] = mu_marg_q_con\n",
    "\n",
    "    limit = np.array([[state[4],state[4]+1],[state[5],state[5]+1]])   \n",
    "    obs_dis= traj_rect_dist(cond_traj.T,  limit)\n",
    "\n",
    "    # mu_1= mean_margs.T.reshape(-1)\n",
    "    mu_2= cond_traj.T.reshape(-1)\n",
    "    # sigma_1 = np.zeros([200,200])\n",
    "    sigma_2 = np.zeros([200,200])\n",
    "    for i in range(100):\n",
    "        # sigma_1[i*2:(i+1)*2,i*2:(i+1)*2] = sigma_s[:,:,i]\n",
    "        sigma_2[i*2:(i+1)*2,i*2:(i+1)*2] = sigma_con_array[:,:,i]\n",
    "    fid_cost= calculate_frechet_distance(mu_1,sigma_1,mu_2,sigma_2) *0.01\n",
    "\n",
    "    alif =0.5\n",
    "#     reward =  alif* fid_cost  -obs_dis*(1-alif)\n",
    "    reward =  obs_dis*(1-alif) - alif* fid_cost \n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a9fdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(cfg, agent):\n",
    "    print('开始训练！')\n",
    "    print(f'环境：{cfg.env_name}, 算法：{cfg.algo_name}, 设备：{cfg.device}')\n",
    "    figure_file = 'plots/cartpole.png'\n",
    "    rewards = []\n",
    "    steps = 0\n",
    "    for i_ep in range(cfg.train_eps):\n",
    "        state = env_reset()\n",
    "        ep_reward = 0\n",
    "            \n",
    "        action, prob, val = agent.choose_action(state)\n",
    "        reward = get_reward(state,action)\n",
    "\n",
    "        ep_reward += reward\n",
    "        agent.memory.push(state, action, prob, val, reward, done)\n",
    "        if steps % cfg.batch_size == 0:\n",
    "            agent.learn()\n",
    "\n",
    "        rewards.append(ep_reward)\n",
    "        if (i_ep + 1) % 10 == 0:\n",
    "            print(f\"回合：{i_ep + 1}/{cfg.train_eps}，奖励：{ep_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bc2fd35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_action(self, state):\n",
    "    state = torch.tensor(state, dtype=torch.float).to(self.device)  # 数组变成张量\n",
    "    dist = self.actor(state)  # action分布\n",
    "    value = self.critic(state)  # state value值\n",
    "    action = dist.sample()  # 随机选择action\n",
    "    prob = torch.squeeze(dist.log_prob(action)).item()  # action对数概率\n",
    "\n",
    "    action = torch.squeeze(action).item()\n",
    "    value = torch.squeeze(value).item()\n",
    "    return action, prob, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88a9bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "   def sample_action(self, state):\n",
    "        state = np.array([state]) # 先转成数组再转tensor更高效\n",
    "        state = torch.tensor(state, dtype=torch.float).to(self.device)\n",
    "        probs = self.actor(state)\n",
    "        dist = Categorical(probs)\n",
    "        value = self.critic(state)\n",
    "        action = dist.sample()\n",
    "        probs = torch.squeeze(dist.log_prob(action)).item()\n",
    "        if self.continuous:\n",
    "            action = torch.tanh(action)\n",
    "        else:\n",
    "            action = torch.squeeze(action).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2c69b00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "# env = gym.make('CartPole-v1')\n",
    "env = gym.make('Pendulum-v1')\n",
    "\n",
    "n_states = env.observation_space.shape[0]\n",
    "print(n_states)\n",
    "n_actions = env.action_space.shape[0]\n",
    "print(n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e41965e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [93]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m action \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m])\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# action = torch.tanh(action)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(action)\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "action = torch.tensor([1,2,3,4])\n",
    "# action = torch.tanh(action)\n",
    "action = torch.squeeze(action).item()\n",
    "\n",
    "print(action)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "42d340d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical(probs: tensor([1.]))\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# probs = torch.FloatTensor([[0.05,0.1,0.85],[0.05,0.05,0.9]])\n",
    "probs = torch.FloatTensor([0.05])\n",
    "dist = Categorical(probs)\n",
    "print(dist)\n",
    "# Categorical(probs: torch.Size([2, 3]))\n",
    " \n",
    "index = dist.sample()\n",
    "print(index.numpy())\n",
    "# [2 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1ba436a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    def __init__(self, n_states, n_actions,  chkpt_dir='/home/zhiyuan/notebook_script/cem_promp/ppo_model'):\n",
    "        super(Actor, self).__init__()\n",
    "#         self.checkpoint_file = os.path.join(chkpt_dir, 'actor_torch_ppo')\n",
    "        self.stds = nn.Parameter(torch.zeros(n_actions))\n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(n_states, 5),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(5,5),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(5, n_actions))\n",
    "            # nn.Softmax(dim=-1))\n",
    "\n",
    "    def forward(self, state):\n",
    "        dist = torch.distributions.Normal(loc=self.actor(state), scale=self.stds.exp())\n",
    "        \n",
    "        return dist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "cdf773d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent.actor(state) \n",
    "\n",
    "actor =Actor(6,3)\n",
    "state= torch.Tensor([0,1,2,3,4,5])\n",
    "# actor(state)\n",
    "dist=actor(state)\n",
    "action = dist.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "092458a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal(loc: torch.Size([3]), scale: torch.Size([3]))\n"
     ]
    }
   ],
   "source": [
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b0b3e9ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.1093, -2.2647, -1.5504], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.log_prob(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d05f1ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.9641942 -1.035494   0.4620923]\n"
     ]
    }
   ],
   "source": [
    " dist.log_prob(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a963ef26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state=[]\n",
    "state.append(ac0)\n",
    "state.append(ac0)\n",
    "state\n",
    "len(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "63d8c2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action:  tensor([-1.3480e+22,  9.9787e+21,  9.4780e+21, -1.9552e+22,  7.5754e+21])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-1.3480e+22,  9.9787e+21,  9.4780e+21, -1.9552e+22,  7.5754e+21],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Policy(nn.Module):\n",
    "    def __init__(self, in_dim, n_hidden_1, n_hidden_2, num_outputs):\n",
    "        super(Policy, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(in_dim, n_hidden_1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(n_hidden_1, n_hidden_2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(n_hidden_2, num_outputs)\n",
    "        )\n",
    "        \n",
    "    \n",
    "\n",
    "class Normal(nn.Module):\n",
    "    def __init__(self, num_outputs):\n",
    "        super().__init__()\n",
    "        self.stds = nn.Parameter(torch.zeros(num_outputs))\n",
    "    def forward(self, x):\n",
    "        dist = torch.distributions.Normal(loc=x, scale=self.stds.exp())\n",
    "        action = dist.sample()\n",
    "        return action\n",
    "\n",
    "policy = Policy(4,20,20,5)\n",
    "normal = Normal(5)\n",
    "observation = torch.Tensor(4)\n",
    "action = normal.forward(policy.layer( observation))\n",
    "\n",
    "print(\"action: \",action)\n",
    "policy.layer( observation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "33d54ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.], grad_fn=<ExpBackward0>)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stds = nn.Parameter(torch.zeros(5))\n",
    "stds.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c4a968",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    def __init__(self, n_states, n_actions, cfg, chkpt_dir='/home/zhiyuan/notebook_script/cem_promp/ppo_model'):\n",
    "        super(Actor, self).__init__()\n",
    "        self.checkpoint_file = os.path.join(chkpt_dir, 'actor_torch_ppo')\n",
    "        self.stds = nn.Parameter(torch.ones(n_actions))*0.1\n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(n_states, cfg.hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(cfg.hidden_dim, cfg.hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(cfg.hidden_dim, n_actions))\n",
    "            # nn.Softmax(dim=-1))\n",
    "\n",
    "    def forward(self, state):\n",
    "        dist = torch.distributions.Normal(loc=self.actor(state), scale=self.stds)\n",
    "        # action = dist.sample()\n",
    "        return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8818573f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a=[]\n",
    "b=torch.randn(3)\n",
    "a.append(b.numpy())\n",
    "a.append(b.numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "05793927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.50802594, -2.4233036 ,  0.63315946], dtype=float32),\n",
       " array([-0.50802594, -2.4233036 ,  0.63315946], dtype=float32)]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "18b3db67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d=np.array(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c30fae40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdf8610",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndarray = np.array(list)  # list 转 numpy数组\n",
    "list = ndarray.tolist()  # numpy 转 list\n",
    "tensor=torch.Tensor(list)  # list 转 torch.Tensor\n",
    "list = tensor.numpy().tolist()  # torch.Tensor 转 list  先转numpy，后转list\n",
    "ndarray = tensor.cpu().numpy()  # torch.Tensor 转 numpy  *gpu上的tensor不能直接转为numpy\n",
    "tensor = torch.from_numpy(ndarray)  # numpy 转 torch.Tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d749dea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob=torch.Tensor([ 0.8182,  1.2037, -0.3921])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "81ae45a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs=[]\n",
    "probs.append(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "38cf43ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 0.8182,  1.2037, -0.3921])]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2d9c6632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.8182,  1.2037, -0.3921])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =probs[0]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1c427b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_env",
   "language": "python",
   "name": "base_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
